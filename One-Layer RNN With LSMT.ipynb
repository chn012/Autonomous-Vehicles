{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os, os.path \n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"new_train/new_train\"\n",
    "pred_path=\"new_val_in/new_val_in\"\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None,p=1.0,test=False):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        self.test=test\n",
    "        self.p=p\n",
    "    def __len__(self):\n",
    "        return int(len(self.pkl_list)*self.p)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if(self.test):\n",
    "            idx+=int(len(self.pkl_list)*self.p)\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "val_dataset  = ArgoverseDataset(data_path=train_path,p=0.15)\n",
    "test_dataset  = ArgoverseDataset(data_path=train_path,p=0.15,test=True)\n",
    "pred_dataset  = ArgoverseDataset(data_path=pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 256\n",
    "\n",
    "#inp_shape [batch_sz,60,19,4]\n",
    "#out_shape [batch_sz,60,30,4]\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     for scene in batch:\n",
    "#         print(scene['p_in'][numpy.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]].shape)\n",
    "#         print(scene['p_in'][numpy.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]])\n",
    "#         print(numpy.where(scene['track_id']==scene['agent_id'])[0])\n",
    "#         print(scene['lane_norm'].shape)\n",
    "#         print(scene['lane_norm'])\n",
    "#         print('lane')\n",
    "#         print(scene['lane'].shape)\n",
    "#         print(scene['lane'])  \n",
    "    inp = [np.dstack([scene['p_in'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]], \n",
    "                         scene['v_in'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]]]) for scene in batch]\n",
    "    out = [np.dstack([scene['p_out'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]],\n",
    "                         scene['v_out'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]]]) for scene in batch]\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    inp = torch.squeeze(inp, 1)\n",
    "    out = torch.squeeze(out, 1)\n",
    "\n",
    "    return [inp, out]\n",
    "\n",
    "#inp_shape [batch_sz,60,19,4]\n",
    "#scene_idx\n",
    "#indecx of each agent in each sence\n",
    "def test_collate(batch):\n",
    "    inp = [np.dstack([scene['p_in'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]], \n",
    "                         scene['v_in'][np.where(scene['track_id'][:,0,:]==scene['agent_id'])[0]]]) for scene in batch]\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    inp = torch.squeeze(inp, 1)\n",
    "    scene_id=[scene['scene_idx'] for scene in batch]\n",
    "    scene_id=torch.IntTensor(scene_id)\n",
    "    # index of the agent vehich \n",
    "#     agent_id_index=[] \n",
    "#      # id of the agent vehich\n",
    "#     scene_id=[]  \n",
    "#     for scene in batch:\n",
    "#         actual_objects=scene['track_id']\n",
    "#         actual_objects=actual_objects[:,0,:]\n",
    "#         agent_id_index.append(numpy.where(actual_objects==scene['agent_id'])[0])\n",
    "#         scene_id.append(scene['scene_idx'])\n",
    "    \n",
    "#     agent_id_index=torch.IntTensor(agent_id_index)\n",
    "    return [inp,scene_id]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=1)\n",
    "pred_loader = DataLoader(pred_dataset,batch_size=batch_sz, shuffle = False, collate_fn=test_collate, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size=4, embedding_size=512, hidden_size=1024):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        \n",
    "        self.embd_dropout = nn.Dropout(0.4)\n",
    "        self.fc=nn.Linear(input_size,embedding_size)\n",
    "        \n",
    "        self.lstm=nn.LSTMCell(embedding_size,hidden_size)\n",
    "        self.lstm1=nn.LSTMCell(hidden_size,hidden_size)\n",
    "        \n",
    "    def forward(self,x:torch.FloatTensor,hidden):\n",
    "        embedded=F.relu(self.fc(x))\n",
    "        embedded = self.embd_dropout(embedded)\n",
    "        hidden = self.lstm(embedded,hidden)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,  embedding_size=512, hidden_size=1024, output_size=4):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embd_dropout = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x,hidden):\n",
    "        embedded = F.relu(self.linear1(x))\n",
    "        embedded = self.embd_dropout(embedded)\n",
    "        hidden = self.lstm1(embedded, hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_seq2seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstm_seq2seq,self).__init__()\n",
    "        self.Encoder=EncoderRNN().to(device)\n",
    "        self.Decoder=DecoderRNN().to(device)\n",
    "    def forward(self,x,forcing=False,out=None):\n",
    "        input_length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "   \n",
    "        encoder_hidden= (\n",
    "            torch.zeros(batch_size, self.Encoder.hidden_size).to(device),\n",
    "            torch.zeros(batch_size, self.Encoder.hidden_size).to(device),\n",
    "        )\n",
    "        for ei in range(input_length-1):\n",
    "            encoder_input = x[:, ei, :]-x[:, ei+1, :]\n",
    "            encoder_hidden = self.Encoder(encoder_input,encoder_hidden)\n",
    "        \n",
    "        rollout_len=30\n",
    "        decoder_input=encoder_input\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        # shape of output batch_size*object timestep feature\n",
    "        decoder_outputs= torch.zeros((x.size(0),rollout_len,x.size(2))).to(device)    \n",
    "        decoder_outputs[:,0,:]=x[:,-1,:]\n",
    "        \n",
    "        \n",
    "        for di in range(rollout_len):\n",
    "            decoder_output, decoder_hidden = self.Decoder(decoder_input,decoder_hidden)\n",
    "            decoder_input=decoder_output\n",
    "            # Update loss\n",
    "            if(di==0):\n",
    "                decoder_outputs[:, di, :] += decoder_output\n",
    "                if forcing:\n",
    "                    decoder_input=out[:,di,:]-x[:,-1,:]\n",
    "            else:\n",
    "                decoder_outputs[:, di, :] = decoder_output+decoder_outputs[:, di-1, :]\n",
    "                if forcing:\n",
    "                    decoder_input=out[:,di,:]-out[:,di-1,:]\n",
    "        return  decoder_outputs\n",
    "#     def predict(self,x):\n",
    "#         input_length = x.shape[1]\n",
    "#         batch_size = x.shape[0]\n",
    "   \n",
    "#         encoder_hidden= (\n",
    "#             torch.zeros(batch_size, self.Encoder.hidden_size).to(device),\n",
    "#             torch.zeros(batch_size, self.Encoder.hidden_size).to(device),\n",
    "#         )\n",
    "#         for ei in range(input_length-1):\n",
    "#             encoder_input = x[:, ei, :]-x[:, ei+1, :]\n",
    "#             encoder_hidden = self.Encoder(encoder_input,encoder_hidden)\n",
    "        \n",
    "#         rollout_len=30\n",
    "#         decoder_input=encoder_input\n",
    "        \n",
    "#         decoder_hidden = encoder_hidden\n",
    "#         # shape of output batch_size*object timestep feature\n",
    "#         decoder_outputs= torch.zeros((x.size(0),rollout_len,x.size(2))).to(device)    \n",
    "#         decoder_outputs[:,0,:]=x[:,-1,:]\n",
    "        \n",
    "#         #loss trnsor\n",
    "#         for di in range(rollout_len):\n",
    "#             decoder_output, decoder_hidden = self.Decoder(decoder_input,decoder_hidden)\n",
    "#             decoder_input = decoder_output\n",
    "#             # Update loss\n",
    "#             if(di==0):\n",
    "#                 decoder_outputs[:, di, :] += decoder_output\n",
    "#             else:\n",
    "#                 decoder_outputs[:, di, :] = decoder_output+decoder_outputs[:, di-1, :]\n",
    "#         return  decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out, perd = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,4, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(4):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "        #axs[i].scatter(out[i,:,0], perd[i,:,1])\n",
    "    plt.show()\n",
    "    \n",
    "# seq2seq rnn\n",
    "def train(val_loader,model,Optimizer,device):\n",
    "    total_loss=0\n",
    "    model.train()\n",
    "    decoder_outputs=0\n",
    "    count=0\n",
    "    for i_batch, sample_batch in enumerate(tqdm(val_loader)):\n",
    "        inp, out = sample_batch\n",
    "        \n",
    "        inp,out=inp.to(device),out.to(device)\n",
    "\n",
    "    \n",
    "        # reshape batch_size*object timestep feature\n",
    "        loss = 0\n",
    "        Optimizer.zero_grad()\n",
    "\n",
    "        # shape of output batch_size*object timestep feature\n",
    "        decoder_outputs=model(inp,forcing=False,out=out)\n",
    "        loss=(torch.mean((decoder_outputs-out)**2))**0.5\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        Optimizer.step()\n",
    "        count+=1\n",
    "\n",
    "        # sample\n",
    "        #show_sample_batch((inp.cpu(),out.cpu(),decoder_outputs.cpu().detach().numpy()))\n",
    "    print(\"total:{}\".format(total_loss/count))    \n",
    "    return total_loss/count\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "#show_sample_batch(sample_batch, agent_id)\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,model,device):\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    count=0\n",
    "    with torch.no_grad():\n",
    "        for inp,out in test_loader:\n",
    "            inp,out=inp.to(device),out.to(device)\n",
    "            decoder_outputs=model(inp)\n",
    "            loss=(torch.mean((decoder_outputs-out)**2))**0.5\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "            count+=1;\n",
    "    return total_loss/count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pred_loader,model,device):\n",
    "    model.eval()\n",
    "    perd_p_out=torch.zeros((1,61)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for inp , scene_id in pred_loader:\n",
    "            inp,scene_id=inp.to(device),scene_id.to(device)\n",
    "\n",
    "            decoder_outputs=model(inp)\n",
    "            batch_size=decoder_outputs.size(0)\n",
    "            # submistion formatting \n",
    "            for i in range(batch_size):\n",
    "                #one agent perdition \n",
    "                temp=torch.cat(((scene_id[i].reshape(1,1)).float(),decoder_outputs[i,:,:2].reshape(60,1)),dim=0).to(device)\n",
    "                temp=temp.reshape(1,61)\n",
    "                #stack all agent perdtion\n",
    "                perd_p_out=torch.cat((perd_p_out,temp),dim=0)         \n",
    "    return perd_p_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model=lstm_seq2seq().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "momentum = 0.9\n",
    "# batch size is 100 \n",
    "# error=nn.MSELoss()\n",
    "# np.exp(-10)\n",
    "learning_rate=0.001\n",
    "Optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(Optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:56<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810089668951744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:35<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.814052337457326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:22<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.808903447852647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8099565466573417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8110156453345434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810077657384321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8144204636250647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8110686786903822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8099686232480137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8101925337610165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.809621227674248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810707486365452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:16<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810338834100518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8063580339605156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810735056222963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:16<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8123882230648323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:20<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8095692839504274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8109742609922552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8134547718300307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8109259644815743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8091372281066644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8119349775235514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8134722552023645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8129976308050235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8076520675470023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.811251644260627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810915950901252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8114457741256587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8097722018060605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8088494627928933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:19<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.811896907396553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.811149853320161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8090712038938666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.810556602872108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:16<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.811868876465096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.812890590715014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8072555084859045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:17<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.809894201184107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:18<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8125011349512525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:16<00:00,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:2.8076817989349365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 40\n",
    "train_loss=np.zeros((num_epoch,))\n",
    "test_loss=np.zeros((num_epoch,))\n",
    "for epoch in range(0, num_epoch):\n",
    "    print(\"epoch\",epoch)\n",
    "    train_loss[epoch]=train(val_loader,model,Optimizer,device)\n",
    "    test_loss[epoch]=test(test_loader,model,device)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21005316\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "x_ax=np.linspace(1, num_epoch, num_epoch)\n",
    "\n",
    "plt.plot(x_ax,train_loss,label='train')\n",
    "plt.plot(x_ax,test_loss,label='test')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(1,5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_p=predict(pred_loader,model,device)\n",
    "#remove the zero\n",
    "sample_p=sample_p[1:,:]\n",
    "\n",
    "for inp,scene_id in pred_loader:\n",
    "    inp,scene_id.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('sample_submission.csv', index_col=False)\n",
    "if is_cuda:\n",
    "    sample_p=sample_p.cpu()\n",
    "sample_p_df=pd.DataFrame(sample_p.numpy(),columns=data.columns)\n",
    "sample_p_df['ID']=sample_p_df['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_p_df.to_csv('sample_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex= torch.zeros((4,)).to(device)\n",
    "# ex_seq=torch.zeros((4,)).to(device)\n",
    "# count=0\n",
    "# for i_batch,sample_batch in enumerate(val_loader):\n",
    "#     inp,out=sample_batch\n",
    "#     inp= inp.to(device).float()\n",
    "#     out= out.to(device).float()\n",
    "#     mixed=torch.cat((inp,out),1).to(device)\n",
    "#     mixed=mixed.reshape((-1,4))\n",
    "#     count=len(mixed)+count\n",
    "#     ex=(ex+torch.sum(mixed,0))\n",
    "#     ex_seq=ex_seq+torch.sum(mixed**2,0)\n",
    "# mean=ex/count\n",
    "# variance=mean**2-ex_seq/count\n",
    "# std=(-variance)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X= [ .....]\n",
    "# for x in X :\n",
    "#     if x is not 0;\n",
    "#         accept \n",
    "#     else \n",
    "#         if m accept w \n",
    "#             accept \n",
    "#         else\n",
    "#             reject "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2651682ea206448e88014e4eddb3fa10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cae5deeb37934a18bfc5fa24b2c84dcd",
        "IPY_MODEL_f18b0035a89b4b0b9ac003c6e0b106f3"
       ],
       "layout": "IPY_MODEL_9dd12bc2db3347989de692da7ba500db"
      }
     },
     "2cdb6fc45a9e4d06bd51ddc56d957120": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "92bdcec2c1194c59964c95a9951b7b93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9dd12bc2db3347989de692da7ba500db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b492e50625544f77a37f7fd44e63ce25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc2f5de58e5944c687b439e191ff9db6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "cae5deeb37934a18bfc5fa24b2c84dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "description": "  4%",
       "layout": "IPY_MODEL_b492e50625544f77a37f7fd44e63ce25",
       "max": 51486,
       "style": "IPY_MODEL_bc2f5de58e5944c687b439e191ff9db6",
       "value": 1881
      }
     },
     "f18b0035a89b4b0b9ac003c6e0b106f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_92bdcec2c1194c59964c95a9951b7b93",
       "style": "IPY_MODEL_2cdb6fc45a9e4d06bd51ddc56d957120",
       "value": " 1881/51486 [04:22&lt;1:55:33,  7.15it/s, loss=2.72e+3]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
